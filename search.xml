<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Python 基础 + 数据可视化</title>
      <link href="/2021/11/04/Python/"/>
      <url>/2021/11/04/Python/</url>
      
        <content type="html"><![CDATA[<div class="note blue flat"><p>记录 python 爬虫的一些知识点 - Forever Settle</p></div><h1 id="爬取豆瓣-Top250-电影信息"><a href="#爬取豆瓣-Top250-电影信息" class="headerlink" title="爬取豆瓣 Top250 电影信息"></a>爬取豆瓣 Top250 电影信息</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup     #网页解析，获取数据</span><br><span class="line">import re       #正则表达式，进行文字匹配</span><br><span class="line">import urllib.request,urllib.error      #制定URL，获取网页数据</span><br><span class="line">import xlwt     #进行excel操作</span><br><span class="line">import sqlite3  #进行SQLite数据库操作</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    baseurl = &quot;https://movie.douban.com/top250?start=&quot;</span><br><span class="line">    #1.爬取网页</span><br><span class="line">    datalist = getData(baseurl)</span><br><span class="line">    #savepath = &quot;豆瓣电影Top250.xls&quot;</span><br><span class="line">    dbpath = &quot;movie.db&quot;</span><br><span class="line">    #3.保存数据</span><br><span class="line">    #saveData(datalist,savepath)</span><br><span class="line">    saveData2DB(datalist,dbpath)</span><br><span class="line"></span><br><span class="line">    #askURL(&quot;https://movie.douban.com/top250?start=&quot;)</span><br><span class="line"></span><br><span class="line">#影片详情链接的规则</span><br><span class="line">findLink = re.compile(r&#x27;&lt;a href=&quot;(.*?)&quot;&gt;&#x27;)     #创建正则表达式对象，表示规则（字符串的模式）</span><br><span class="line">#影片图片</span><br><span class="line">findImgSrc = re.compile(r&#x27;&lt;img.*src=&quot;(.*?)&quot;&#x27;,re.S)   #re.S 让换行符包含在字符中</span><br><span class="line">#影片片名</span><br><span class="line">findTitle = re.compile(r&#x27;&lt;span class=&quot;title&quot;&gt;(.*)&lt;/span&gt;&#x27;)</span><br><span class="line">#影片评分</span><br><span class="line">findRating = re.compile(r&#x27;&lt;span class=&quot;rating_num&quot; property=&quot;v:average&quot;&gt;(.*)&lt;/span&gt;&#x27;)</span><br><span class="line">#找到评价人数</span><br><span class="line">findJudge = re.compile(r&#x27;&lt;span&gt;(\d*)人评价&lt;/span&gt;&#x27;)</span><br><span class="line">#找到概况</span><br><span class="line">findInq = re.compile(r&#x27;&lt;span class=&quot;inq&quot;&gt;(.*)&lt;/span&gt;&#x27;)</span><br><span class="line">#找到影片的相关内容</span><br><span class="line">findBd = re.compile(r&#x27;&lt;p class=&quot;&quot;&gt;(.*?)&lt;/p&gt;&#x27;,re.S)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#爬取网页</span><br><span class="line">def getData(baseurl):</span><br><span class="line">    datalist = []</span><br><span class="line">    for i in range(0,10):       #调用获取页面信息的函数，10次</span><br><span class="line">        url = baseurl</span><br><span class="line">        html = askURL(url)      #保存获取到的网页源码</span><br><span class="line"></span><br><span class="line">        # 2.逐一解析数据</span><br><span class="line">        soup = BeautifulSoup(html,&quot;html.parser&quot;)</span><br><span class="line">        for item in soup.find_all(&#x27;div&#x27;,class_=&quot;item&quot;):     #查找符合要求的字符串，形成列表</span><br><span class="line">            #print(item)   #测试：查看电影item全部信息</span><br><span class="line">            data = []    #保存一部电影的所有信息</span><br><span class="line">            item = str(item)</span><br><span class="line"></span><br><span class="line">            #影片详情的链接</span><br><span class="line">            link = re.findall(findLink,item)[0]     #re库用来通过正则表达式查找指定的字符串</span><br><span class="line">            data.append(link)                       #添加链接</span><br><span class="line"></span><br><span class="line">            imgSrc = re.findall(findImgSrc,item)[0]</span><br><span class="line">            data.append(imgSrc)                     #添加图片</span><br><span class="line"></span><br><span class="line">            titles = re.findall(findTitle,item)     #片名可能只有一个中文名，没有外国名</span><br><span class="line">            if(len(titles) == 2):</span><br><span class="line">                ctitle = titles[0]                  #添加中文名</span><br><span class="line">                data.append(ctitle)</span><br><span class="line">                otitle = titles[1].replace(&quot;/&quot;,&quot;&quot;)  #去掉无关的符号</span><br><span class="line">                data.append(otitle)                 #添加外国名</span><br><span class="line">            else:</span><br><span class="line">                data.append(titles[0])</span><br><span class="line">                data.append(&#x27; &#x27;)        #外国名字留空</span><br><span class="line"></span><br><span class="line">            rating = re.findall(findRating,item)[0]</span><br><span class="line">            data.append(rating)                        #添加评分</span><br><span class="line"></span><br><span class="line">            judgeNum = re.findall(findJudge,item)[0]</span><br><span class="line">            data.append(judgeNum)                       #提加评价人数</span><br><span class="line"></span><br><span class="line">            inq = re.findall(findInq,item)</span><br><span class="line">            if len(inq) != 0:</span><br><span class="line">                inq = inq[0].replace(&quot;。&quot;,&quot;&quot;)    #去掉句号</span><br><span class="line">                data.append(inq)                # 添加概述</span><br><span class="line">            else:</span><br><span class="line">                data.append(&quot; &quot;)                #留空</span><br><span class="line"></span><br><span class="line">            bd = re.findall(findBd,item)[0]</span><br><span class="line">            bd = re.sub(&#x27;&lt;br(\s+)?/&gt;(\s+)?&#x27;,&quot; &quot;,bd)   #去掉&lt;br/&gt;</span><br><span class="line">            bd = re.sub(&#x27;/&#x27;,&quot; &quot;,bd)     #替换/</span><br><span class="line">            data.append(bd.strip())     #去掉前后的空格</span><br><span class="line"></span><br><span class="line">            datalist.append(data)       #把处理好的一部电影信息放入datalist</span><br><span class="line">            #print(datalist)</span><br><span class="line">    return datalist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#得到指定一个URL的网页内容</span><br><span class="line">def askURL(url):</span><br><span class="line">    head = &#123;                #模拟浏览器头部信息，向豆瓣服务器发送消息</span><br><span class="line">        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    #用户代理，表示告诉豆瓣服务器，我们是什么类型的机器、浏览器（本质上是告诉浏览器，我们可以接收什么水平的文件内容）</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url,headers=head) #发起一个请求把head传进去</span><br><span class="line">    html = &quot;&quot;</span><br><span class="line">    try:</span><br><span class="line">        response = urllib.request.urlopen(request)</span><br><span class="line">        html = response.read().decode(&quot;utf-8&quot;) #解析</span><br><span class="line">        #print(html)</span><br><span class="line">    except urllib.error.URLError as e:</span><br><span class="line">        if hasattr(e,&quot;code&quot;):</span><br><span class="line">            print(e.code)</span><br><span class="line">        if hasattr(e,&quot;reason&quot;):</span><br><span class="line">            print(e.reason)</span><br><span class="line">    return html</span><br><span class="line"></span><br><span class="line">#保存数据</span><br><span class="line">def saveData(datalist,savepath):</span><br><span class="line">    print(&quot;save....&quot;)</span><br><span class="line">    book = xlwt.Workbook(encoding=&quot;utf-8&quot;,style_compression=0)  #创建workbook对象</span><br><span class="line">    sheet = book.add_sheet(&#x27;豆瓣电影Top250&#x27;,cell_overwrite_ok=True)    #创建工作表</span><br><span class="line">    col = (&quot;电影详情链接&quot;,&quot;图片链接&quot;,&quot;影片中文名&quot;,&quot;影片外国名&quot;,&quot;评分&quot;,&quot;评价数&quot;,&quot;概况&quot;,&quot;相关信息&quot;)</span><br><span class="line">    for i in range(0,8):</span><br><span class="line">        sheet.write(0,i,col[i]) #列名</span><br><span class="line">    for i in range(0,250):</span><br><span class="line">        print(&quot;第%d条&quot; %(i+1))</span><br><span class="line">        data = datalist[i]</span><br><span class="line">        for j in range(0,8):</span><br><span class="line">            sheet.write(i+1,j,data[j])      #数据</span><br><span class="line"></span><br><span class="line">    book.save(savepath)       #保存</span><br><span class="line"></span><br><span class="line">def saveData2DB(datalist,dbpath):</span><br><span class="line">    init_db(dbpath)</span><br><span class="line">    conn=sqlite3.connect(dbpath)</span><br><span class="line">    cur=conn.cursor()</span><br><span class="line">    for data in datalist:</span><br><span class="line">        for index in range(len(data)):</span><br><span class="line">            if index ==4 or index==5:</span><br><span class="line">                continue</span><br><span class="line">            data[index]=&#x27;&quot;&#x27;+data[index]+&#x27;&quot;&#x27;</span><br><span class="line">        sql=&#x27;&#x27;&#x27;insert into movie250 (</span><br><span class="line">                   info_link,pic_link,cname,ename,score,rated,introduction,info)</span><br><span class="line">                   values(%s)&#x27;&#x27;&#x27;%&quot;,&quot;.join(data)</span><br><span class="line">        print(sql)</span><br><span class="line">        cur.execute(sql)</span><br><span class="line">        conn.commit()</span><br><span class="line">    cur.close()</span><br><span class="line">    conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def init_db(dbpath):</span><br><span class="line">    sql=&#x27;&#x27;&#x27;</span><br><span class="line">        create table movie250</span><br><span class="line">        (</span><br><span class="line">        id integer primary key autoincrement,</span><br><span class="line">        info_link text,</span><br><span class="line">        pic_link text,</span><br><span class="line">        cname varchar ,</span><br><span class="line">        ename varchar ,</span><br><span class="line">        score numeric,</span><br><span class="line">        rated numeric,</span><br><span class="line">        introduction text,</span><br><span class="line">        info text </span><br><span class="line">        )</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    conn=sqlite3.connect(dbpath)</span><br><span class="line">    cursor=conn.cursor()</span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:          #当程序执行时</span><br><span class="line">    #调用函数</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line">    #init_db(&quot;movietest.db&quot;)</span><br><span class="line">    print(&quot;爬取完毕！&quot;)</span><br></pre></td></tr></table></figure><h1 id="爬取西南计院录取信息"><a href="#爬取西南计院录取信息" class="headerlink" title="爬取西南计院录取信息"></a>爬取西南计院录取信息</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">#得到指定一个url网页内容</span><br><span class="line">import re</span><br><span class="line">import urllib.request</span><br><span class="line">import xlwt</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def askURL(url):</span><br><span class="line">    header = &#123;</span><br><span class="line">        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    # 用户代理告诉浏览器我们可以接受什么水平的文本</span><br><span class="line">    request = urllib.request.Request(url, headers=header)</span><br><span class="line">    html = &quot;&quot;</span><br><span class="line">    try:</span><br><span class="line">        response = urllib.request.urlopen(request)</span><br><span class="line">        html = response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">        #print(html)</span><br><span class="line">    except urllib.error.URLError as e:</span><br><span class="line">        if hasattr(e, &quot;code&quot;):</span><br><span class="line">            print(e.code)</span><br><span class="line">        if hasattr(e, &quot;reason&quot;):</span><br><span class="line">            print(e.reason)</span><br><span class="line">    return html</span><br><span class="line"></span><br><span class="line">#爬取网页</span><br><span class="line">def getData(baseurl):</span><br><span class="line">    datalist=[]</span><br><span class="line">    for i in range(0,1):#调用获取页面信息的函数10次</span><br><span class="line">       url=baseurl</span><br><span class="line">       html=askURL(url)#保存获取道德网页</span><br><span class="line">       # 逐一解析数据</span><br><span class="line">       soup=BeautifulSoup(html,&quot;html.parser&quot;)</span><br><span class="line">       for item in soup.find_all(&#x27;tr&#x27;,style=&quot;height: 17px;&quot;):</span><br><span class="line">          #print(item)#查看电影item全部信息</span><br><span class="line">          data=[]#保存一部电影的全部信息</span><br><span class="line">          item=str(item)</span><br><span class="line">          Num1=re.findall(findNum,item)[0]</span><br><span class="line">          data.append(Num1)</span><br><span class="line"></span><br><span class="line">          Name=re.findall(findName,item)[0]</span><br><span class="line">          data.append(Name)</span><br><span class="line"></span><br><span class="line">          Num2=re.findall(findNum,item)[1]</span><br><span class="line">          data.append(Num2)</span><br><span class="line">          Num3=re.findall(findNum,item)[2]</span><br><span class="line">          data.append(Num3)</span><br><span class="line">          Num4=re.findall(findNum,item)[3]</span><br><span class="line">          data.append(Num4)</span><br><span class="line">          Num5=re.findall(findNum,item)[4]</span><br><span class="line">          data.append(Num5)</span><br><span class="line">          Num6=re.findall(findNum,item)[5]</span><br><span class="line">          data.append(Num6)</span><br><span class="line">          Ru=re.findall(findName,item)[1]</span><br><span class="line">          data.append(Ru)</span><br><span class="line">          datalist.append(data) #把处理好的一部电影信息放入datalist</span><br><span class="line">          #print(datalist) #查找符合要求的字符串形成列表</span><br><span class="line">    return datalist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def saveData(datalist,savepath):</span><br><span class="line">    print(&quot;save....&quot;)</span><br><span class="line">    book=xlwt.Workbook(encoding=&quot;utf-8&quot;,style_compression=0) #创建workbook对象</span><br><span class="line">    sheet=book.add_sheet(&#x27;2021西南大学计算机学院复试名单&#x27;,cell_overwrite_ok=True) #创建工作表</span><br><span class="line">    col=(&#x27;考生编号&#x27;,&quot;姓名&quot;,&quot;政治成绩&quot;,&quot;外国语成绩&quot;,&quot;业务课一成绩&quot;,&quot;业务课二成绩&quot;,&quot;初试总成绩&quot;,&quot;备注&quot;) #写入数据 第一个参数”行“，第二个参数”列“，第三个参数内容</span><br><span class="line">    for i in range(0,8):</span><br><span class="line">        sheet.write(0,i,col[i])#列名</span><br><span class="line">    for i in range(0,197):</span><br><span class="line">        print(&quot;第%d条&quot; %(i+1))</span><br><span class="line">        data=datalist[i]</span><br><span class="line">        for j in range(0,8):</span><br><span class="line">            sheet.write(i+1,j,data[j])#数据</span><br><span class="line">    book.save(savepath)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    baseurl=&quot;http://cis.swu.edu.cn/s/cis/zsjy/20210325/4413251.html&quot;</span><br><span class="line">    #1爬取网页</span><br><span class="line">    datalist=getData(baseurl)</span><br><span class="line">    savepath=&quot;2021西南大学计算机学院复试名单.xls&quot;</span><br><span class="line">    #3保存数据</span><br><span class="line">    saveData(datalist,savepath)</span><br><span class="line"></span><br><span class="line">    #askURL(baseurl)</span><br><span class="line"></span><br><span class="line">#数字相关包括分数和考生编号</span><br><span class="line">findNum=re.compile(r&#x27;&lt;span style=&quot;font-family: Times New Roman;&quot;&gt;(\d*)&lt;/span&gt;&#x27;)</span><br><span class="line">#姓名及备注 文字信息</span><br><span class="line">findName=re.compile(r&#x27;&lt;span style=&quot;font-family: 宋体;&quot;&gt;(.*?)&lt;/span&gt;&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    #调用函数</span><br><span class="line">    main()</span><br><span class="line">    print(&quot;爬取完毕&quot;)</span><br></pre></td></tr></table></figure><h1 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h1><p>主要借助 Flask 框架、Echarts、WordCloud 等技术实现</p><h2 id="模板网站"><a href="#模板网站" class="headerlink" title="模板网站"></a>模板网站</h2><p><a href="http://www.cssmoban.com/"></a></p><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p><img src="https://z3.ax1x.com/2021/05/22/gLMtN4.png" alt=""></p><h2 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h2><p>app.py<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">from flask import Flask,render_template</span><br><span class="line">import sqlite3</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/&#x27;)</span><br><span class="line">def index():</span><br><span class="line">    return render_template(&quot;index.html&quot;)</span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/index&#x27;)</span><br><span class="line">def home():</span><br><span class="line">    return index()</span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/movie&#x27;)</span><br><span class="line">def movie():</span><br><span class="line">    datalist=[]</span><br><span class="line">    con=sqlite3.connect(&quot;movie.db&quot;)</span><br><span class="line">    cur=con.cursor()</span><br><span class="line">    sql=&quot;select * from movie250&quot;</span><br><span class="line">    data=cur.execute(sql)</span><br><span class="line">    for item in data:</span><br><span class="line">        datalist.append(item)</span><br><span class="line">    cur.close()</span><br><span class="line">    con.close()</span><br><span class="line">    return render_template(&quot;movie.html&quot;,movies=datalist)</span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/score&#x27;)</span><br><span class="line">def score():</span><br><span class="line">     score=[] #评分</span><br><span class="line">     num=[] #评分人数</span><br><span class="line">     con=sqlite3.connect(&quot;movie.db&quot;)</span><br><span class="line">     cur=con.cursor()</span><br><span class="line">     sql=&quot;select score,count(score) from movie250 group by score&quot;</span><br><span class="line">     data=cur.execute(sql)</span><br><span class="line">     for item in data:</span><br><span class="line">        score.append(item[0])</span><br><span class="line">        num.append(item[1])</span><br><span class="line">     cur.close()</span><br><span class="line">     con.close()</span><br><span class="line">     return render_template(&quot;score.html&quot;,score=score,num=num)</span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/team&#x27;)</span><br><span class="line">def team():</span><br><span class="line">    return render_template(&quot;team.html&quot;)</span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/word&#x27;)</span><br><span class="line">def word():</span><br><span class="line">    return render_template(&quot;word.html&quot;)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure><br>testCloud.py<br>// 利用 wordcloud 生成词云，这里用了树形遮罩图片<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">import jieba#分词</span><br><span class="line">from matplotlib import pyplot as plt #绘图数据可视化</span><br><span class="line">from wordcloud import WordCloud #词云</span><br><span class="line">from PIL import Image #图片处理</span><br><span class="line">import numpy as np #矩阵运算</span><br><span class="line">import sqlite3 #数据库</span><br><span class="line"></span><br><span class="line">#准备词云所需的文字或者词</span><br><span class="line">con=sqlite3.connect(&#x27;movie.db&#x27;)</span><br><span class="line">cur=con.cursor()</span><br><span class="line">sql=&#x27;select introduction from movie250&#x27;</span><br><span class="line">data=cur.execute(sql)</span><br><span class="line">text=&quot;&quot;</span><br><span class="line">for item in data:</span><br><span class="line">    text=text+item[0]</span><br><span class="line">#print(text)</span><br><span class="line">cur.close()</span><br><span class="line">con.close()</span><br><span class="line"></span><br><span class="line">#分词</span><br><span class="line">cut=jieba.cut(text)</span><br><span class="line">string=&#x27; &#x27;.join(cut)</span><br><span class="line">#print(string)</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">img=Image.open(r&#x27;.\static\assets\img\tree.jpg&#x27;) #打开遮罩图片</span><br><span class="line">img_array=np.array(img) #将图片转换为数组</span><br><span class="line">wc=WordCloud(</span><br><span class="line">    background_color=&#x27;white&#x27;,</span><br><span class="line">    mask=img_array,</span><br><span class="line">    font_path=&quot;msyhl.ttc&quot;</span><br><span class="line">)</span><br><span class="line">wc.generate_from_text(string)</span><br><span class="line"></span><br><span class="line">#绘制图片</span><br><span class="line">fig =plt.figure(1)</span><br><span class="line">plt.imshow(wc)</span><br><span class="line">plt.axis(&#x27;off&#x27;)#是否显示坐标轴</span><br><span class="line"></span><br><span class="line"># plt.show()#显示生成的词云图片</span><br><span class="line"></span><br><span class="line">plt.savefig(r&#x27;.\static\assets\img\word.jpg&#x27;,dpi=500)</span><br></pre></td></tr></table></figure><br>需要爬取得到的 movie.db 作为数据源<br><img src="https://z3.ax1x.com/2021/05/22/gLMDu6.png" alt=""></p><h2 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h2><p><img src="https://z3.ax1x.com/2021/05/22/gLM7VS.png" alt=""></p><p><img src="https://z3.ax1x.com/2021/05/22/gL1d3j.png" alt=""></p><p><img src="https://z3.ax1x.com/2021/05/22/gL1hvR.png" alt=""></p><p><img src="https://z3.ax1x.com/2021/05/22/gL3UZ6.png" alt=""></p><h1 id="异步加载网页爬取"><a href="#异步加载网页爬取" class="headerlink" title="异步加载网页爬取"></a>异步加载网页爬取</h1><p>异步加载通常指一些需要加载更多的网页如 b 站评论、NHK 新闻或者当前网页无法爬取，多是通过 json 进行爬取<br>首先网址不应是当前页面地址而应该是 json 地址<br>这里选择爬取 51job 网站</p><h1 id="几个需要注意的点"><a href="#几个需要注意的点" class="headerlink" title="几个需要注意的点"></a>几个需要注意的点</h1><ol><li>间隔时间爬取</li><li>用代理</li></ol>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Python 深度学习》笔记</title>
      <link href="/2021/11/04/Machine-Learning/"/>
      <url>/2021/11/04/Machine-Learning/</url>
      
        <content type="html"><![CDATA[<div class="note blue flat"><p>记录机器学习的一些知识点 - Forever Settle</p></div><h1 id="第一章-什么是深度学习"><a href="#第一章-什么是深度学习" class="headerlink" title="第一章 什么是深度学习"></a>第一章 什么是深度学习</h1><h2 id="人工智能、机器学习与深度学习"><a href="#人工智能、机器学习与深度学习" class="headerlink" title="人工智能、机器学习与深度学习"></a>人工智能、机器学习与深度学习</h2><p><img src="https://www.hualigs.cn/image/609fe5bc31dba.jpg" alt="三者之间的关系"></p><h3 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h3><p>简洁的定义：努力将通常由人类完成的智力任务自动化。</p><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><p>虽然符号主义人工智能适合用来解决定义明确的逻辑问题，但它难以给出明确的规则来解决更加复杂、模糊的问题，比如图像分类、语音识别和语言翻译。于是出现了一种新的方法来替代符号主义人工智能，这就是机器学习（machine learning）。<br>机器学习：一种新的编程范式<br>机器学习系统是训练出来的，而不是明确地用程序编写出来的。将与某个任务相关的许多示例输入机器学习系统，它会在这些示例中找到统计结构， 从而最终找到规则将任务自动化。举个例子，你想为度假照片添加标签，并且希望将这项任务自动化，那么你可以将许多人工打好标签的照片输入机器学习系统，系统将学会将照片与特定标签联系在一起的统计规则。</p><h3 id="从数据中学习表示"><a href="#从数据中学习表示" class="headerlink" title="从数据中学习表示"></a>从数据中学习表示</h3><p>我们需要一下三个要素来进行机器学习：</p><p>①. 输入数据点。例如，你的任务是语音识别，那么这些数据点可能是记录人们说话的声音文件。如果你的任务是为图像添加标签，那么这些数据点可能是图像。<br>②. 预期输出的示例。对于语音识别任务来说，这些示例可能是人们根据声音文件整理生成的文本。对于图像标记任务来说，预期输出可能是 “狗”“猫” 之类的标签。<br>③. 衡量算法效果好坏的方法。这一衡量方法是为了计算算法的当前输出与预期输出的差距。衡量结果是一种反馈信号，用于调节算法的工作方式。这个调节步骤就是我们所说的学习。</p><p>机器学习模型将输入数据变换为有意义的输出，这是一个从已知的输入和输出示例中进行 “学习” 的过程。机器学习中的学习指的是，寻找更好数据表示的自动搜索过程。</p><p>机器学习的技术定义：在预先定义好的可能性空间中，利用反馈信号的指引来寻找输入数据的有用表示。</p><h3 id="深度学习之”-深度”"><a href="#深度学习之”-深度”" class="headerlink" title="深度学习之” 深度”"></a>深度学习之” 深度”</h3><p>深度学习强调从连续的层（layer）中进行学习，这些层对应于越来越有意义的表示。“深度学习” 中的 “深度” 指的是一系列连续的表示层。数据模型中包含多少层，这被称为模型的 “深度（depth）”。</p><p>用于数字分类的深度神经网络</p><p>数字图像分类模型学到的深度表示</p><p>这个网络将数字图像转换成与原始图像差别越来越大的表示，而其中关于最终结果的信息却越来越丰富。可以将深度网络看做多级信息蒸馏操作：信息穿过连续的过滤器，其纯度越来越高（即对任务的帮助越来越大）。</p><p>深度学习的技术定义：学习数据表示的多级方法。</p><h3 id="深度学习的工作原理"><a href="#深度学习的工作原理" class="headerlink" title="深度学习的工作原理"></a>深度学习的工作原理</h3><p>神经网络中每层对输入数据所做的具体操作保存在该层的权重（weight）中，其本质是一串数字。 用术语来说，每层实现的变换由其权重来参数化（parameterize）。 学习的意思是为神经网络的所有层找到一组权重值，使得该网络能够将每个示例输入与其目标正确地一一对应。</p><p>神经网络是由其权重来参数化</p><p>想要控制神经网络的输出，就需要能够衡量该输出与预期值之间的距离。这是神经网络损失函数（loss function）的任务。</p><p>损失函数用来衡量网络输出结果的质量</p><p>深度学习的基本技巧是利用这个距离值作为反馈信号来对权重值进行微调，以降低当前示例对应的损失值。这种调节由优化器（optimizer）完成， 它实现了所谓的反向传播（backpropagation）算法（下一章介绍），这是深度学习的核心算法。</p><p>将损失值作为反馈信号来调节权重</p><p>一开始对神经网络的权重随机赋值，因此网络只是实现了一系列随机变换。其输出结果自然也和理想值相去甚远，相应地，损失值也很高。但随着网络处理的示例越来越多，权重值也在向正确的方向逐步微调，损失值也逐渐降低。这就是训练循环（training loop）。</p><h1 id="第二章-神经网络的数学基础"><a href="#第二章-神经网络的数学基础" class="headerlink" title="第二章 神经网络的数学基础"></a>第二章 神经网络的数学基础</h1><h2 id="神经网络的数据表示"><a href="#神经网络的数据表示" class="headerlink" title="神经网络的数据表示"></a>神经网络的数据表示</h2><p>当前所有机器学习系统都使用张量作为基本数据结构。<br>张量是一个数据容器，包含的数据几乎总是数值数据，是矩阵向任意维度的推广。张量的维度通常叫做轴</p><h3 id="标量（0D-张量）"><a href="#标量（0D-张量）" class="headerlink" title="标量（0D 张量）"></a>标量（0D 张量）</h3><p>仅包含一个数字的张量叫做标量（scalar）或 0 维张量，有 0 个轴。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import numpy as np</span><br><span class="line">&gt;&gt;&gt; x = np.array(12)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array(12)</span><br><span class="line">&gt;&gt;&gt; x.ndim</span><br><span class="line">0</span><br></pre></td></tr></table></figure></p><h3 id="向量（1D-张量）"><a href="#向量（1D-张量）" class="headerlink" title="向量（1D 张量）"></a>向量（1D 张量）</h3><p>数字组成的数组叫做向量（vector）或一维张量（1D 张量），有 1 个轴。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.array([12, 3, 6, 14, 7])</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([12, 3, 6, 14, 7])</span><br><span class="line">&gt;&gt;&gt; x.ndim</span><br><span class="line">1</span><br></pre></td></tr></table></figure></p><h3 id="矩阵（2D-张量）"><a href="#矩阵（2D-张量）" class="headerlink" title="矩阵（2D 张量）"></a>矩阵（2D 张量）</h3><p>向量组成的数组叫做矩阵（matrix）或二维张量（2D 张量）。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.array([[5, 78, 2, 34, 0],</span><br><span class="line">[6, 79, 3, 35, 1],</span><br><span class="line">[7, 80, 4, 36, 2]])</span><br><span class="line">&gt;&gt;&gt; x.ndim</span><br><span class="line">2</span><br></pre></td></tr></table></figure></p><h3 id="3D-张量与更高维张量"><a href="#3D-张量与更高维张量" class="headerlink" title="3D 张量与更高维张量"></a>3D 张量与更高维张量</h3><p>将多个矩阵组合成一个新的数组，可以得到一个 3D 张量。 将多个 3D 张量组合成一个数组，可以创建一个 4D 张量。</p><p>深度学习处理的一般都是 0D 到 4D 的张量，但处理视频数据时可能会遇到 5D 张量</p><h3 id="关键属性"><a href="#关键属性" class="headerlink" title="关键属性"></a>关键属性</h3><p>张量是由一下三个关键属性来定义的：</p><p>轴的个数（阶，ndim）。3D 张量有 3 个轴，矩阵有 2 个轴。<br>形状（shape）。是一个整数元组，表示张量沿每个轴的维度大小（元素个数）。矩阵示例形状：{3,5}；3D 张量示例形状：{3,3,5}。<br>数据类型（dtype）：可以是 float32、uint8、float64 等。</p><h3 id="在-Numpy-中操作张量"><a href="#在-Numpy-中操作张量" class="headerlink" title="在 Numpy 中操作张量"></a>在 Numpy 中操作张量</h3><p>选择张量的特定元素叫做张量切片（tensor slicing）。</p><p>例子：选择 10-100 个数字（不包括 100），并将其放在形状为（90,28,28）的数组中。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; my_slice = train_images[10:100]</span><br><span class="line">&gt;&gt;&gt; print(my_slice.shape)</span><br><span class="line">(90, 28, 28)</span><br><span class="line"># 等同于：</span><br><span class="line">&gt;&gt;&gt; my_slice = train_images[10:100, :, :]</span><br><span class="line">&gt;&gt;&gt; my_slice.shape</span><br><span class="line">(90, 28, 28)</span><br><span class="line">&gt;&gt;&gt; my_slice = train_images[10:100, 0:28, 0:28]</span><br><span class="line">&gt;&gt;&gt; my_slice.shape</span><br><span class="line">(90, 28, 28)</span><br></pre></td></tr></table></figure></p><h3 id="数据批量的概念"><a href="#数据批量的概念" class="headerlink" title="数据批量的概念"></a>数据批量的概念</h3><p>深度学习中数据张量的第一个轴（0 轴）都是样本轴（samples axis，样本维度）。</p><p>深度学习模型不会同时处理整个数据集，而是将数据拆分成小批量。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#批量大小为128</span><br><span class="line">batch = train_images&amp;#123;:128&amp;#125;</span><br><span class="line">#然后是下一个批量</span><br><span class="line">batch = train_images&amp;#123;128:256&amp;#125;</span><br><span class="line">#然后是第n个批量</span><br><span class="line">batch = train_images[128 * n:128 * (n + 1)]</span><br></pre></td></tr></table></figure><br>对于这种批量张量。第一个轴（0 轴）叫做批量轴（batch axis） 或 批量维度（batch dimension）。</p><h3 id="现实世界中的数据张量"><a href="#现实世界中的数据张量" class="headerlink" title="现实世界中的数据张量"></a>现实世界中的数据张量</h3><p>现实中要处理的数据几乎总是以下类别之一：</p><p>向量数据：2D 张量，形状为 (samples, features)。</p><p>时间序列数据或序列数据：3D 张量，形状为 (samples, timesteps,features)。</p><p>图像：4D 张量，形状为 (samples, height, width, channels) 或 (samples,channels,height, width)。</p><p>视频：5D 张量，形状为 (samples, frames, height, width, channels) 或 (samples,frames, channels, height, width)。</p><h3 id="向量数据"><a href="#向量数据" class="headerlink" title="向量数据"></a>向量数据</h3><p>每个数据点都被编码为一个向量，因此一个数据批量就被编码为 2D 张量，其中第一个轴是样本轴， 第二个轴是特征轴。</p><h3 id="时间序列数据或序列数据"><a href="#时间序列数据或序列数据" class="headerlink" title="时间序列数据或序列数据"></a>时间序列数据或序列数据</h3><p>每个样本可以被编码为一个向量序列（即 2D 张量），因此一个数据批量就被编码为一个 3D 张量。</p><h3 id="图像数据"><a href="#图像数据" class="headerlink" title="图像数据"></a>图像数据</h3><p>图像通常具有三个维度：高度、宽度和颜色深度。图像张量时钟都是 3D 张量。</p><p>128 张大小为 256×256 的灰度图像组成的批量可以保存在大小为 {128,256,256,1} 张量。</p><p>128 张彩色图像：{128,256,256,3}。</p><p>图像数据组成的 4D 张量<br>图像数据组成的 4D 张量</p><p>TensorFlow 中遵循通道在后的约定，即将颜色深度轴放在最后：{samples,height,width,color_depth}</p><h3 id="视频数据"><a href="#视频数据" class="headerlink" title="视频数据"></a>视频数据</h3><p>保存在 5D 张量中：{samples,frame,height,width,color_depth}</p><h2 id="神经网络的-“齿轮”：张量运算"><a href="#神经网络的-“齿轮”：张量运算" class="headerlink" title="神经网络的 “齿轮”：张量运算"></a>神经网络的 “齿轮”：张量运算</h2><h3 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h3><p>将两个形状不同的张量相加，较小的张量会被广播（broadcast），以匹配较大张量的形状。</p><p>步骤：</p><p>①. 向较小的张量添加轴（叫作广播轴），使其 ndim 与较大的张量相同。<br>②. 将较小的张量沿着新轴重复，使其形状与较大的张量相同。</p><h3 id="张量点积"><a href="#张量点积" class="headerlink" title="张量点积"></a>张量点积</h3><p>两个向量之间的点积是一个标量，一个矩阵和一个向量做点积的结果是一个向量。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">z = np.dot(x, y)</span><br></pre></td></tr></table></figure></p><h3 id="张量变形"><a href="#张量变形" class="headerlink" title="张量变形"></a>张量变形</h3><p>指改变张量的行和列。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.array([[0., 1.],</span><br><span class="line">[2., 3.],</span><br><span class="line">[4., 5.]])</span><br><span class="line">&gt;&gt;&gt; print(x.shape)</span><br><span class="line">(3, 2)</span><br><span class="line">&gt;&gt;&gt; x = x.reshape((6, 1))</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[ 0.],[ 1.],[ 2.],[ 3.],[ 4.],[ 5.]])</span><br><span class="line">&gt;&gt;&gt; x = x.reshape((2, 3))</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([[ 0., 1., 2.],</span><br><span class="line">[ 3., 4., 5.]])</span><br></pre></td></tr></table></figure></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.zeros((300, 20))</span><br><span class="line">&gt;&gt;&gt; x = np.transpose(x)</span><br><span class="line">&gt;&gt;&gt; print(x.shape)</span><br><span class="line">(20, 300)</span><br></pre></td></tr></table></figure><h3 id="深度学习的几何解释"><a href="#深度学习的几何解释" class="headerlink" title="深度学习的几何解释"></a>深度学习的几何解释</h3><p>神经网络完全由一系列张量运算组成，而这些张量运算都只是输入数据的几何变换。深度网络的每一层都通过变换使数据解开一点点 —— 许多层堆叠在一起，可以实现非常复杂的解开过程</p><h2 id="神经网络的-“引擎”：基于梯度的优化"><a href="#神经网络的-“引擎”：基于梯度的优化" class="headerlink" title="神经网络的 “引擎”：基于梯度的优化"></a>神经网络的 “引擎”：基于梯度的优化</h2><p>一个训练循环的具体过程：</p><p>①. 抽取训练样本 x 和对应目标 y 组成的数据批量。<br>②. 在 x 上运行网络［这一步叫作前向传播（forward pass）］，得到预测值 y_pred。<br>③. 计算网络在这批数据上的损失，用于衡量 y_pred 和 y 之间的距离。<br>④. 计算损失相对于网络参数的梯度［一次反向传播（backward pass）］。<br>⑤. 将参数沿着梯度的反方向移动一点，比如 W -= step * gradient，从而使这批数据上的损失减小一点。</p><p>这叫小批量随机梯度下降（mini-batch stochastic gradient descent，小批量 SGD）。</p><p>此外，SGD 还有多种变体，其区别在于计算下一次权重更新时还要考虑上一次权重更新，而不是仅仅考虑当前梯度值，比如带动量的 SGD、Adagrad、RMSProp 等变体。这些变体被称为优化方法（optimization method）或优化器（optimizer）。其中动量的引入可以使优化过程避免进入局部极小点。</p><h1 id="第三章-神经网络入门"><a href="#第三章-神经网络入门" class="headerlink" title="第三章 神经网络入门"></a>第三章 神经网络入门</h1><h2 id="神经网络剖析"><a href="#神经网络剖析" class="headerlink" title="神经网络剖析"></a>神经网络剖析</h2><p>训练神经网络主要围绕以下四个方面：</p><p>①. 层，多个层组合成网络（或模型）。<br>②. 输入数据和相应的 目标。<br>③. 损失函数，即用于学习的反馈信号。<br>④. 优化器，决定学习过程如何进行。</p><h3 id="层：深度学习的基础组件"><a href="#层：深度学习的基础组件" class="headerlink" title="层：深度学习的基础组件"></a>层：深度学习的基础组件</h3><p>神经网络的基本数据结构是层。层是一个数据处理模块，将一个或多个输入张量转换为一个或多个输出张量。</p><p>不同的张量格式与不同的数据处理类型需要用到不同的层。例如，简单的向量数据保存在形状为 (samples, features) 的 2D 张量中，通常用全连接层（对应于 Keras 的 Dense 类）来处理。序列数据保存在形状为 (samples, timesteps, features) 的 3D 张量中，通常用循环层（recurrent layer，比如 Keras 的 LSTM 层）来处理。图像数据保存在 4D 张量中，通常用二维卷积层（Keras 的 Conv2D）来处理。</p><h3 id="模型：层构成的网络"><a href="#模型：层构成的网络" class="headerlink" title="模型：层构成的网络"></a>模型：层构成的网络</h3><p>深度学习模型是层构成的有向无环图。最常见的例子就是层的线性堆叠，将单一输入映射为单一输出。</p><p>一些常见的网络拓扑结构：双分支（two-branch）网络、多头（multihead）网络、Inception 模块。</p><p>网络的拓扑结构定义了一个假设空间（hypothesis space）。选定了网络拓扑结构，意味着将假设空间限定为一系列特定的张量运算，将输入数据映射为输出数据。然后，你需要为这些张量运算的权重张量找到一组合适的值。</p><h3 id="损失函数与优化器：配置学习过程的关键"><a href="#损失函数与优化器：配置学习过程的关键" class="headerlink" title="损失函数与优化器：配置学习过程的关键"></a>损失函数与优化器：配置学习过程的关键</h3><p>一旦确定了网络架构，还需要选择一下两个参数：</p><p>损失函数 —— 在训练过程中需要将其最小化。它能够衡量当前任务是否已经成功完成。<br>优化器 —— 决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降（SGD）的某个变体。<br>具有多个输出的神经网络可能具有多个损失函数（每个输出对应一个损失函数）。但是，梯度下降过程必须基于单个标量损失值。因此，对于具有多个损失函数的网络，需要将所有损失函数取平均，变为一个标量值。</p><p>可以遵循一些简单的指导原则来选择正确的损失函数：</p><p>①. 二分类问题：使用二元交叉熵（binary crossentropy）损失函数；</p><p>②. 多分类问题：使用分类交叉熵（categorical crossentropy）损失函数；</p><p>③. 回归问题：均方误差（mean-squared error）损失函数；</p><p>④. 序列学习问题：联结主义时序分类（CTC, connectionist temporal classification）损失函数。</p><h2 id="Keras-简介"><a href="#Keras-简介" class="headerlink" title="Keras 简介"></a>Keras 简介</h2><h3 id="Keras、TensorFlow"><a href="#Keras、TensorFlow" class="headerlink" title="Keras、TensorFlow"></a>Keras、TensorFlow</h3><p>Keras 是一个模型级（model-level）的库，为开发深度学习模型提供了高层次的构建模块。它不处理张量操作、求微分等低层次的运算。相反，它依赖于一个专门的、高度优化的张量库来完成这些运算，这个张量库就是 Keras 的后端引擎（backend engine）。Keras 没有选择单个张量库并将 Keras 实现与这个库绑定，而是以模块化的方式处理这个问题。因此，几个不同的后端引擎都可以无缝嵌入到 Keras 中。</p><p>深度学习的软件栈和硬件栈<br>深度学习的软件栈和硬件栈</p><p>通过 TensorFlow（或 Theano、CNTK），Keras 可以在 CPU 和 GPU 上无缝运行。在 CPU 上运行时，TensorFlow 本身封装了一个低层次的张量运算库，叫作 Eigen；在 GPU 上运行时，TensorFlow 封装了一个高度优化的深度学习运算库，叫作 NVIDIA CUDA 深度神经网络库（cuDNN）。</p><h3 id="使用-Keras-开发：概述"><a href="#使用-Keras-开发：概述" class="headerlink" title="使用 Keras 开发：概述"></a>使用 Keras 开发：概述</h3><p>典型 Keras 工作流程：</p><p>①. 定义训练数据：输入张量和目标张量。<br>②. 定义层组成的网络（或模型），将输入映射到目标。<br>③. 配置学习过程：选择损失函数、优化器和需要监控的指标。<br>④. 调用模型的 fit 方法在训练数据上进行迭代。</p><p>定义模型有两种方法：一种是使用 Sequential 类（仅用于层的线性堆叠，这是目前最常见的网络架构），另一种是函数式 API（functional API，用于层组成的有向无环图，让你可以构建任意形式的架构）。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#一个利用Sequential类定义的两层模型</span><br><span class="line">from keras import models</span><br><span class="line">from keras import layers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(32, activation=&#x27;relu&#x27;, input_shape=(784,)))</span><br><span class="line">model.add(layers.Dense(10, activation=&#x27;softmax&#x27;))</span><br></pre></td></tr></table></figure><br>配置学习过程是在编译这一步，你需要指定模型使用的优化器和损失函数，以及训练过程中想要监控的指标。下面是单一损失函数的例子，这也是目前最常见的。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from keras import optimizers</span><br><span class="line">model.compile(optimizer=optimizers.RMSprop(lr=0.001),</span><br><span class="line">               loss=&#x27;mse&#x27;,</span><br><span class="line">               metrics=[&#x27;accuracy&#x27;])</span><br></pre></td></tr></table></figure><br>最后，学习过程就是通过 fit () 方法将输入数据的 Numpy 数组（和对应的目标数据）传入模型。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)</span><br></pre></td></tr></table></figure></p><h2 id="新闻分类-——-多分类问题"><a href="#新闻分类-——-多分类问题" class="headerlink" title="新闻分类 —— 多分类问题"></a>新闻分类 —— 多分类问题</h2><p>应该从这个例子中学到的要点：</p><p>①. 如果要对 N 个类别的数据点进行分类，网络的最后一层应该是大小为 N 的 Dense 层。<br>②. 对于单标签、多分类问题，网络的最后一层应该使用 softmax 激活，这样可以输出在 N 个输出类别上的概率分布。<br>③. 这种问题的损失函数几乎总是应该使用分类交叉熵（categorical crossentropy）。它将网络输出的概率分布与目标的真实分布之间的距离最小化。<br>④. 处理多分类问题的标签有两种方法。<br>通过分类编码（也叫 one-hot 编码）对标签进行编码，然后使用 categorical_<br>crossentropy 作为损失函数。<br>将标签编码为整数，然后使用 sparse_categorical_crossentropy 损失函数。<br>⑤. 如果你需要将数据划分到许多类别中，应该避免使用太小的中间层，以免在网络中造成信息瓶颈。</p><h1 id="第四章-机器学习基础"><a href="#第四章-机器学习基础" class="headerlink" title="第四章 机器学习基础"></a>第四章 机器学习基础</h1><h2 id="机器学习的四个分支"><a href="#机器学习的四个分支" class="headerlink" title="机器学习的四个分支"></a>机器学习的四个分支</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>给定一组样本（通常由人工标注），它可以学会将输入数据映射到已知目标［也叫标注（annotation）］。一般来说，近年来广受关注的深度学习应用几乎都属于监督学习，比如光学字符识别、语音识别、图像分类和语言翻译。</p><p>监督学习主要包括分类回归，但也有其它变体（在此先暂不讨论）。</p><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>无监督学习是指在没有目标的情况下寻找输入数据的有趣变换，其目的在于数据可视化、数据压缩、数据去噪或更好地理解数据中的相关性。降维 （dimensionality reduction）和聚类（clustering）都是众所周知的无监督学习方法。</p><h3 id="自监督学习"><a href="#自监督学习" class="headerlink" title="自监督学习"></a>自监督学习</h3><p>自监督学习是没有人工标注的标签的监督学习，标签是从输入数据中生成的，通常是使用启发式算法生成的。</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>在强化学习中，智能体（agent）接收有关其环境的信息，并学会选择使某种奖励最大化的行动。例如，神经网络会 “观察” 视频游戏的屏幕并输出游戏操作，目的是尽可能得高分，这种神经网络可以通过强化学习来训练。</p><h2 id="评估机器学习模型"><a href="#评估机器学习模型" class="headerlink" title="评估机器学习模型"></a>评估机器学习模型</h2><p>随着训练的进行，模型在训练数据上的性能始终在提高，但在前所未见的数据上的性能则可能不再变化或者开始下降，这就是过拟合。</p><p>机器学习的目的是得到可以泛化（generalize）的模型，即在前所未见的数据上表现很好的模型，而过拟合则是核心难点。</p><h3 id="几种经典的评估方法"><a href="#几种经典的评估方法" class="headerlink" title="几种经典的评估方法"></a>几种经典的评估方法</h3><p>1.简单的留出验证<br>简单的留出验证数据划分</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">num_validation_samples = 10000</span><br><span class="line"></span><br><span class="line">np.random.shuffle(data) # 通常需要打乱数据</span><br><span class="line"></span><br><span class="line">validation_data = data[:num_validation_samples] # 定义验证集</span><br><span class="line">data = data[num_validation_samples:]</span><br><span class="line"></span><br><span class="line">training_data = data[:] # 定义训练集</span><br><span class="line"></span><br><span class="line">#在训练数据上训练模型，并在验证数据上评估模型</span><br><span class="line">model = get_model()</span><br><span class="line">model.train(training_data)</span><br><span class="line">validation_score = model.evaluate(validation_data)</span><br><span class="line"></span><br><span class="line">#现在你可以调节模型、重新训练、评估，然后再次调节……</span><br><span class="line"></span><br><span class="line">#一旦调节好超参数，通常就在所有非测试数据上从头开始训练最终模型</span><br><span class="line">model = get_model()</span><br><span class="line">model.train(np.concatenate([training_data,validation_data]))</span><br><span class="line">test_score = model.evaluate(test_data)</span><br></pre></td></tr></table></figure><p>缺点：如果可用的数据很少，那么可能验证集和测试集包含的样本就太少，从而无法在统计学上代表数据。如果在划分数据前进行不同的随机打乱，最终得到的模型性能差别很大。<br>1.K 折验证<br>K 折验证（K-fold validation）将数据划分为大小相同的 K 个分区。对于每个分区 i，在剩余的 K-1 个分区上训练模型，然后在分区 i 上评估模型。最终分数等于 K 个分数的平均值。</p><p>2.带有打乱数据的重复 K 折验证<br>是多次使用 K 折验证，在每次将数据划分为 K 个分区之前都先将数据打乱。最终分数是每次 K 折验证分数的平均值。注意，这种方法一共要训练和评估 P×K 个模型（P 是重复次数），计算代价很大。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">k = 4</span><br><span class="line">num_validation_samples = len(data) // k</span><br><span class="line"></span><br><span class="line">np.random.shuffle(data) # 打乱数据</span><br><span class="line"></span><br><span class="line">validation_scores = []</span><br><span class="line">for fold in range(k):</span><br><span class="line"># 选择验证数据分区</span><br><span class="line">validation_data = data[num_validation_samples * fold:</span><br><span class="line">num_validation_samples * (fold + 1)]</span><br><span class="line"># 使用剩余数据作为训练数据，“+”运算符是列表合并，不是求和</span><br><span class="line">training_data = data[:num_validation_samples * fold] +</span><br><span class="line">data[num_validation_samples * (fold + 1):]</span><br><span class="line"></span><br><span class="line">    # 创建一个全新的模型实例(未训练)</span><br><span class="line">    model = get_model()</span><br><span class="line">    model.train(training_data)</span><br><span class="line">    validation_score = model.evaluate(validation_data)</span><br><span class="line">    validation_scores.append(validation_score)</span><br><span class="line"></span><br><span class="line"># 最终验证分数：K折验证分数的平均值</span><br><span class="line">validation_score = np.average(validation_scores)</span><br><span class="line"></span><br><span class="line"># 在所有非测试数据上训练最终模型</span><br><span class="line">model = get_model()</span><br><span class="line">model.train(data)</span><br><span class="line">test_score = model.evaluate(test_data)</span><br></pre></td></tr></table></figure></p><h2 id="数据预处理、特征工程和特征学习"><a href="#数据预处理、特征工程和特征学习" class="headerlink" title="数据预处理、特征工程和特征学习"></a>数据预处理、特征工程和特征学习</h2><h3 id="神经网络的数据预处理"><a href="#神经网络的数据预处理" class="headerlink" title="神经网络的数据预处理"></a>神经网络的数据预处理</h3><p>数据预处理的目的是使原始数据更适于用神经网络处理。</p><ul><li>向量化:<br>神经网络的所有输入和目标都必须是浮点数张量（在特定情况下可以是整数张量）。无论处理什么数据（声音、图像还是文本），都必须首先将其转换为张量，这一步叫作数据向量化（data vectorization）。</li></ul><ul><li>值标准化:<br>为了让网络的学习变得更容易，输入数据应该具有以下特征：  取值较小：大部分值都应该在 0-1 范围内<br>同质性：所有特征的取值都应该在大致相同的范围内</li></ul><ul><li>处理缺失值:<br>如果不是所有样本都具有这个特征的话，那样你的训练数据或测试数据将会有缺失值。一般来说，对于神经网络，将缺失值设置为 0 是安全的，只要 0 不是一个有意义的值。网络能够从数据中学到 0 意味着缺失数据，并且会忽略这个值。</li></ul><p>注意，如果测试数据中可能有缺失值，而网络是在没有缺失值的数据上训练的，那么网络不可能学会忽略缺失值。在这种情况下，你应该人为生成一些有缺失项的训练样本：多次复制一些训练样本，然后删除测试数据中可能缺失的某些特征。</p><h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>特征工程（feature engineering）是指将数据输入模型之前，利用你自己关于数据和机器学习算法（这里指神经网络）的知识对数据进行硬编码的变换（不是模型学到的），以改善模型的效果。多数情况下，一个机器学习模型无法从完全任意的数据中进行学习。呈现给模型的数据应该便于模型进行学习。</p><p>特征工程的本质：用更简单的方式表述问题，从而使问题变得更容易。它通常需要深入理解问题。</p><p>对于现代深度学习，大部分特征工程都是不需要的，因为神经网络能够从原始数据中自动提取有用的特征</p><h2 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h2><p>机器学习的根本问题是优化和泛化之间的对立。优化（optimization）是指调节模型以在训练数据上得到最佳性能（即机器学习中的学习）， 而泛化（generalization）是指训练好的模型在前所未见的数据上的性能好坏。</p><p>训练开始时，优化和泛化是相关的：训练数据上的损失越小，测试数据上的损失也越小，这时的模型是欠拟合（underfit）的。但在训练数据上迭代一定次数之后，泛化不再提高，验证指标先是不变，然后开始变差， 即模型开始过拟合。这时模型开始学习仅和训练数据有关的模式，但这种模式对新数据来说是错误的或无关紧要的。</p><p>防止过拟合的最优解决方法是获取更多的训练数据，模型的训练数据越多，泛化能力自然也越好。如果无法获取更多数据，次优解决方法是调节模型允许存储的信息量，或对模型允许存储的信息加以约束。如果一个网络只能记住几个模式，那么优化过程会迫使模型集中学习最重要的模式，这样更可能得到良好的泛化。这种降低过拟合的方法叫做正则化（regularization）。下面介绍几种最常见的正则化方法。</p><h3 id="减少网络大小"><a href="#减少网络大小" class="headerlink" title="减少网络大小"></a>减少网络大小</h3><p>防止过拟合的最简单的方法就是减小模型大小，即减少模型中可学习参数的个数（这由层数和每层的单元个数决定）。在深度学习中，模型中可学习参数的个数通常被称为模型的容量（capacity）。 直观上来看，参数更多的模型拥有更大的记忆容量（memorization capacity），因此能够在训练样本和目标之间轻松地学会完美的字典式映射，这种映射没有任何泛化能力。</p><h3 id="添加权重正则化"><a href="#添加权重正则化" class="headerlink" title="添加权重正则化"></a>添加权重正则化</h3><p>一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加规则（regular）。这种方法叫作权重正则化（weight regularization），其实现方法是向网络损失函数中添加与较大权重值相关的成本（cost）。这个成本有两种形式。<br>①.L1 正则化（L1 regularization） ：添加的成本与权重系数的绝对值［权重的 L1 范数（norm）］成正比。<br>②. L2 正则化（L2 regularization）：添加的成本与权重系数的平方（权重的 L2 范数）成正比。神经网络的 L2 正则化也叫权重衰减（weight decay）。不要被不同的名称搞混，权重衰减与 L2 正则化在数学上是完全相同的。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from keras import regularizers</span><br><span class="line"></span><br><span class="line">#向分类网络中添加L2权重正则化</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),activation=&#x27;relu&#x27;, input_shape=(10000,)))</span><br><span class="line">model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(layers.Dense(1, activation=&#x27;sigmoid&#x27;))</span><br></pre></td></tr></table></figure><br>l2 (0.001) 的意思是该层权重矩阵的每个系数都会使网络总损失增加 0.001 weight_coefficient_value。注意，由于这个惩罚项 * 只在训练时添加，所以这个网络的训练损失会比测试损失大很多。<br>还可以用以下这些权重正则化来代替 L2 正则化：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from keras import regularizers</span><br><span class="line"></span><br><span class="line">regularizers.l1(0.001) # L1正则化</span><br><span class="line"></span><br><span class="line">regularizers.l1_l2(l1=0.001, l2=0.001) # 同时做L1和L2正则化</span><br></pre></td></tr></table></figure></p><h3 id="添加-dropout-正则化"><a href="#添加-dropout-正则化" class="headerlink" title="添加 dropout 正则化"></a>添加 dropout 正则化</h3><p>dropout 是神经网络最有效也最常用的正则化方法之一。对某一层使用 dropout，就是在训练过程中随机将该层的一些输出特征舍弃（设置为 0）。其核心思想是在层的输出值中引入噪声，打破不显著的偶然模式（Hinton 称之为阴谋）。如果没有噪声的话，网络将会记住这些偶然模式。</p><p>dropout 比率（dropout rate）是被设为 0 的特征所占的比例，通常在 0.2~0.5 范围内。</p><p>向分类网络中添加两个 Dropout 层，看一下它们降低过拟合的效果。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#通过Dropout 层向网络中引入dropout，dropout 将被应用于前面一层的输出。</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(16, activation=&#x27;relu&#x27;, input_shape=(10000,)))</span><br><span class="line">model.add(layers.Dropout(0.5))</span><br><span class="line">model.add(layers.Dense(16, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(layers.Dropout(0.5))</span><br><span class="line">model.add(layers.Dense(1, activation=&#x27;sigmoid&#x27;))</span><br></pre></td></tr></table></figure></p><h2 id="机器学习的通用工作流程"><a href="#机器学习的通用工作流程" class="headerlink" title="机器学习的通用工作流程"></a>机器学习的通用工作流程</h2><h3 id="定义问题、收集数据集"><a href="#定义问题、收集数据集" class="headerlink" title="定义问题、收集数据集"></a>定义问题、收集数据集</h3><p>首先，你必须定义所面对的问题。</p><p>你的输入数据是什么？你要预测什么？只有拥有可用的训练数据，你才能学习预测某件事情。比如，只有同时拥有电影评论和情感标注，你才能学习对电影评论进行情感分类。因此，数据可用性通常是这一阶段的限制因素。</p><p>你面对的是什么类型的问题？是二分类问题、多分类问题、标量回归问题、向量回归问题，还是多分类、多标签问题？或者是其他问题，比如聚类、生成或强化学习？确定问题类型有助于你选择模型架构、损失函数等。</p><p>只有明确了输入、输出以及所使用的数据，你才能进入下一阶段。注意你在这一阶段所做的假设。</p><p>假设输出是可以根据输入进行预测的。<br>假设可用数据包含足够多的信息，足以学习输入和输出之间的关系。</p><h3 id="选择衡量成功的指标"><a href="#选择衡量成功的指标" class="headerlink" title="选择衡量成功的指标"></a>选择衡量成功的指标</h3><p>对于多分类问题，成功的定义就是分类的精度。 可以使用平均准确率均值（mean average precision）作为指标。</p><h3 id="确定评估方法"><a href="#确定评估方法" class="headerlink" title="确定评估方法"></a>确定评估方法</h3><p>三种常见的评估方法：</p><p>留出验证集：数据量很大时采用</p><p>K 折交叉验证：如果留出验证的样本量太少时可以采用</p><p>重复的 K 折验证：如果可用的数据很少，同时模型评估又需要非常准确，那么应该使用这种方法</p><h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><p>将数据格式化，使其可以输入到机器学习模型中。</p><p>数据格式化为张量<br>张量的取值通常应该缩放为较小的值，比如在 $[-1,1]$ 区间或 $[0,1]$ 区间<br>如果不同特征具有不同的取值范围，那么应该做数据标准化<br>可能需要做特征工程，尤其是对于小数据问题</p><h3 id="开发比基准更好的模型"><a href="#开发比基准更好的模型" class="headerlink" title="开发比基准更好的模型"></a>开发比基准更好的模型</h3><p>开发一个小型模型，它能够打败纯随机的基准，即获得统计功效。</p><p>想获得统计功效，必须有两个假设：</p><p>假设输出是可以根据输入进行预测的<br>假设可用的数据包含足够多的信息，足以学习输入和输出之间的关系<br>如果一切顺利，还需要选择三个关键参数来构建第一个构建模型：</p><p>①. 最后一层的激活。它对网络输出进行有效的限制。例如，IMDB 分类的例子在最后一层使用了 sigmoid，回归的例子在最后一层没有使用激活，等等。<br>②. 损失函数。它应该匹配你要解决的问题的类型。例如，IMDB 的例子使用 binary_crossentropy、回归的例子使用 mse，等等。<br>③. 优化配置。你要使用哪种优化器？学习率是多少？大多数情况下，使用 rmsprop 及其默认的学习率是稳妥的。</p><p>为模型选择正确的最后一层激活和损失函数</p><h3 id="扩大模型规模：开发过拟合的模型"><a href="#扩大模型规模：开发过拟合的模型" class="headerlink" title="扩大模型规模：开发过拟合的模型"></a>扩大模型规模：开发过拟合的模型</h3><p>机器学习中无处不在的对立是优化和泛化的对立，理想的模型是刚好在欠拟合和过拟合的界线上，在容量不足和容量过大的界线上。为了找到这条界线，必须穿过它。</p><p>要搞清楚需要多大的模型，就必须开发一个过拟合的模型：</p><p>①. 添加更多的层。<br>②. 让每一层变得更大。<br>③. 训练更多的轮次。</p><p>要始终监控训练损失和验证损失，以及你所关心的指标的训练值和验证值。如果你发现模型在验证数据上的性能开始下降，那么就出现了过拟合。</p><p>下一阶段开始正则化和调节模型，以便尽可能地接近理想模型，既不过拟合也不欠拟合。</p><h3 id="模型正则化与调节超参数"><a href="#模型正则化与调节超参数" class="headerlink" title="模型正则化与调节超参数"></a>模型正则化与调节超参数</h3><p>这一步最费时间</p><p>你将不断地调节模型、训练、在验证数据上评估（这里不是测试数据）、再次调节模型，然后重复这一过程，直到模型达到最佳性能。你应该尝试以下几项。</p><p>①. 添加 dropout。<br>②. 尝试不同的架构：增加或减少层数。<br>③. 添加 L1 和 / 或 L2 正则化。<br>④. 尝试不同的超参数（比如每层的单元个数或优化器的学习率），以找到最佳配置。<br>⑤.（可选）反复做特征工程：添加新特征或删除没有信息量的特征。</p><p>一旦开发出令人满意的模型配置，你就可以在所有可用数据（训练数据 + 验证数据）上训练最终的生产模型，然后在测试集上最后评估一次。如果测试集上的性能比验证集上差很多，那么这可能意味着你的验证流程不可靠，或者你在调节模型参数时在验证数据上出现了过拟合。在这种情况下，你可能需要换用更加可靠的评估方法，比如重复的 K 折验证。</p><h1 id="第五章-深度学习用于计算机视觉"><a href="#第五章-深度学习用于计算机视觉" class="headerlink" title="第五章 深度学习用于计算机视觉"></a>第五章 深度学习用于计算机视觉</h1><h2 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h2><h3 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h3><p>密集连接层和卷积层的根本区别在于，Dense 层从输入特征空间中学到的是全局模式，而卷积层学到的是局部模式，对于图像来说，学到的就是在输入图像的二维小窗口中发现的模式。</p><p>图像可以被分解为局部模式，如边缘、纹理等<br>图像可以被分解为局部模式，如边缘、纹理等</p><p>这个重要特性使卷积神经网络具有以下两个有趣的性质。</p><p>卷积神经网络学到的模式具有平移不变性（translation invariant）。卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式，比如左上角。对于密集连接网络来说，如果模式出现在新的位置，它只能重新学习这个模式。 这使得卷积神经网络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。<br>卷积神经网络可以学到模式的空间层次结构（spatial hierarchies of patterns）。第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的更大的模式，以此类推。这使得卷积神经网络可以有效地学习越来越复杂、越来越抽象的视觉概念 （因为视觉世界从根本上具有空间层次结构）。<br>对于包含两个空间轴（高度和宽度） 和一个深度轴（也叫通道轴）的 3D 张量， 其卷积也叫特征图（feature map）。对于 RGB 图像，深度轴的维度大小等于 3，因为图像有 3 个颜色通道：红色、绿色和蓝色。对于黑白图像（比如 MNIST 数字图像），深度等于 1（表示灰度等级）。卷积运算从输入特征图中提取图块，并对所有这些图块应用相同的变换， 生成输出特征图（output feature map）。该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是代表 过滤器（filter）。</p><p>视觉世界形成了视觉模块的空间层次结构：超局部的边缘组合成局部的对象，<br>比如眼睛或耳朵，这些局部对象又组合成高级概念，比如 “猫”<br>视觉世界形成了视觉模块的空间层次结构：超局部的边缘组合成局部的对象，<br>比如眼睛或耳朵，这些局部对象又组合成高级概念，比如 “猫”</p><p>在 MNIST 示例中，第一个卷积层接收一个大小为 (28, 28, 1) 的特征图，并输出一个大小为 (26, 26, 32) 的特征图，即它在输入上计算 32 个过滤器。对于这 32 个输出通道，每个通道都包含一个 26×26 的数值网格，它是过滤器对输入的响应图（response map），表示这个过滤器模式在输入中不同位置的响应。 这也是特征图这一术语的含义：深度轴的每个维度都是一个特征（或过滤器）， 而 2D 张量 output [:, :, n] 是这个过滤器在输入上的响应的二维空间图（map）。</p><p>响应图的概念：某个模式在输入中的不同位置是否存在的二维图<br>响应图的概念：某个模式在输入中的不同位置是否存在的二维图</p><p>卷积由以下两个关键参数所定义:<br>①. 从输入中提取的图块尺寸：这些图块的大小通常是 3×3 或 5×5。<br>②. 输出特征图的深度：卷积所计算的过滤器的数量。</p><p>对于 Keras 的 Conv2D 层，这些参数都是向层传入的前几个参数：Conv2D (output_depth,(window_height, window_width))。</p><p>卷积的工作原理：在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_depth)］。然后每个 3D 图块与学到的同一个权重矩阵［叫作卷积核（convolution kernel）］做张量积，转换成形状为 (output_depth,) 的 1D 向量。然后对所有这些向量进行空间重组，使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。输出特征图中的每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信息）。举个例子，利用 3×3 的窗口，向量 output [i, j, :] 来自 3D 图块 input [i-1:i+1,j-1:j+1, :]。</p><h3 id="卷积的工作原理"><a href="#卷积的工作原理" class="headerlink" title="卷积的工作原理"></a>卷积的工作原理</h3><p>卷积的工作原理<br>注意，输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。<br>①. 边界效应，可以通过对输入特征图进行填充来抵消。如果你希望输出特征图的空间维度与输入相同，那么可以使用填充（padding）。填充是在输入特征图的每一边添加适当数目的行和列，使得每个输入方块都能作为卷积窗口的中心。对于 Conv2D 层，可以通过 padding 参数来设置填充，这个参数有两个取值：”valid” 表示不使用填充（只使用有效的窗口位置）；”same“表示 “填充后输出的宽度和高度与输入相同”。padding 参数的默认值为”valid”。<br>②. 使用了步幅（stride）。两个连续窗口的距离是卷积的一个参数，叫作步幅，默认值为 1。 也可以使用步进卷积（strided convolution），即步幅大于 1 的卷积。步幅为 2 意味着特征图的宽度和高度都被做了 2 倍下采样（除了边界效应引起的变化）。</p><p>为了对特征图进行下采样，我们不用步幅，而是通常使用最大池化（max-pooling）运算。</p><h3 id="最大池化运算"><a href="#最大池化运算" class="headerlink" title="最大池化运算"></a>最大池化运算</h3><p>最大池化的作用：对特征图进行下采样。最大池化使用硬编码的 max 张量运算对局部图块进行变换，而不是学到的线性变换（卷积核）。最大池化通常使用 2×2 的窗口和步幅 2，其目的是将特征图下采样 2 倍。</p><p>使用下采样的原因，一是减少需要处理的特征图的元素个数，二是通过让连续<br>卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine-Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>百年孤独</title>
      <link href="/2021/11/03/Book/"/>
      <url>/2021/11/03/Book/</url>
      
        <content type="html"><![CDATA[<div class="note blue icon flat"><i class="note-icon fas fa-bullhorn"></i><p>“他的小说以丰富的想象编织了一个现实与幻想交相辉映的世界，反映了一个大陆的生命与矛盾 “ —— 瑞典学院</p></div><p><img src="https://www.hualigs.cn/image/609f7d46385bf.jpg" alt=""></p><h1 id="First"><a href="#First" class="headerlink" title="First"></a>First</h1><p>他在没有爱情的荒漠中所结识的那些女人，多得不可胜数，她们把他的种子撒播在整个加勒比海岸，但没有在他的感情上留下一丝痕迹。她们大多是摸黑进房来，拂晓前离去，第二天他醒来时，只有对她们肉体的一点索然无味的回忆。<br>一个幸福晚年的秘决不是别的，而是与孤寂签订一个体面的协定。</p><h1 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h1><p>某些人的爱情，只是一种当时的情绪，如果对方错将这份情绪当做长远的感情，是本身的幼稚。<br>你如此憎恶军人，跟他们打了这么多的仗，对他们琢磨了这么久，到头来还是成了同他们一样的人。人生中没有比这更卑贱的理想了。<br>死亡跟他没有什么关系，而生命对他才有意义。</p><h1 id="Third"><a href="#Third" class="headerlink" title="Third"></a>Third</h1><p>她身上披着蔑视一切的厚厚的盔甲，这是世间的任何诱惑都无法刺破的。<br>这个家庭的历史是一架周而复始无法停息的机器，是一个转动着的轮子，这只齿轮，要不是轴会逐渐不可避免地磨损的话，会永远旋转下去。——(哥伦比亚) 加西亚・马尔克斯《百年孤独》<br>每一个生命都有灵魂，只是怎样唤醒他们…… ——(哥伦比亚) 加西亚・马尔克斯《百年孤独》<br>他没有察觉到时光在家里造成的细微而又令人心碎的破坏，这么长日子外出之后，对任何一个有着清晰记忆的人来说，这种破坏都会觉得是一种灾难。<br>上帝似乎决意要考验一下人们的全部惊讶能力，他让马贡多的人们总是处于不停的摇摆和游移之中，一会儿高兴，一会儿失望；一会儿百思不解，一会儿疑团冰释，以至谁也搞不清现实的界限究竟在哪里。<br>我们打了这么多年仗，一切只不过是为了别把我们的房子涂成蓝色。</p><h1 id="End"><a href="#End" class="headerlink" title="End"></a>End</h1><p>并不是聊得来，就适合在一起；并不是适合，就能够在一起；并不是能够在一起就会永远在一起；也并不是永远在一起了就会幸福的。<br>这个无奇不有的世界上也一定会有一个男人以他无以伦比的无所谓态度来对付她的。</p>]]></content>
      
      
      <categories>
          
          <category> Book </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/11/03/hello-world/"/>
      <url>/2021/11/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/%20_data/link.json"/>
      <url>/%20_data/link.json</url>
      
        <content type="html"><![CDATA[[{"class_name":"友情鏈接","class_desc":"那些人，那些事","link_list":[{"name":"Hexo","link":"https://hexo.io/zh-tw/","avatar":"https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg","descr":"快速、簡單且強大的網誌框架"}]},{"class_name":"網站","class_desc":"值得推薦的網站","link_list":[{"name":"Youtube","link":"https://www.youtube.com/","avatar":"https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png","descr":"視頻網站"},{"name":"Weibo","link":"https://www.weibo.com/","avatar":"https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png","descr":"中國最大社交分享平台"},{"name":"Twitter","link":"https://twitter.com/","avatar":"https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png","descr":"社交分享平台"}]}]]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>archives</title>
      <link href="/archives/index.html"/>
      <url>/archives/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>about</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>link</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>图库</title>
      <link href="/gallery/index.html"/>
      <url>/gallery/index.html</url>
      
        <content type="html"><![CDATA[<div class="gallery-group-main">  <figure class="gallery-group">  <img class="gallery-group-img" src='https://www.hualigs.cn/image/60a0e62c4ea81.jpg' alt="Group Image Gallery">  <figcaption>  <div class="gallery-group-name">壁紙</div>  <p>收藏的一些壁紙</p>  <a href='/gallery/gallery1'></a>  </figcaption>  </figure>    <figure class="gallery-group">  <img class="gallery-group-img" src='https://i.loli.net/2019/12/25/8t97aVlp4hgyBGu.jpg' alt="Group Image Gallery">  <figcaption>  <div class="gallery-group-name">漫威</div>  <p>關於漫威的圖片</p>  <a href='/gallery/gallery2'></a>  </figcaption>  </figure>    <figure class="gallery-group">  <img class="gallery-group-img" src='https://i.loli.net/2019/12/25/hOqbQ3BIwa6KWpo.jpg' alt="Group Image Gallery">  <figcaption>  <div class="gallery-group-name">OH MY GIRL</div>  <p>關於OH MY GIRL的圖片</p>  <a href='/gallery/gallery3'></a>  </figcaption>  </figure>  </div>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>音乐</title>
      <link href="/music/index.html"/>
      <url>/music/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>talk</title>
      <link href="/talk/index.html"/>
      <url>/talk/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>gallery1</title>
      <link href="/gallery/gallery1/index.html"/>
      <url>/gallery/gallery1/index.html</url>
      
        <content type="html"><![CDATA[<div class="justified-gallery"><p><img src="https://www.hualigs.cn/image/609fd775e8a7b.jpg" alt=""></p>          </div>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>gallery1</title>
      <link href="/gallery/gallery2/index.html"/>
      <url>/gallery/gallery2/index.html</url>
      
        <content type="html"><![CDATA[<div class="justified-gallery"><p><img src="https://www.hualigs.cn/image/60a0e62c4ea81.jpg" alt=""><br><img src="https://www.hualigs.cn/image/60a0e62b10935.jpg" alt=""><br><img src="https://www.hualigs.cn/image/60a0e62b8a821.jpg" alt=""></p>          </div>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>gallery1</title>
      <link href="/gallery/gallery3/index.html"/>
      <url>/gallery/gallery3/index.html</url>
      
        <content type="html"><![CDATA[<div class="justified-gallery"><p><img src="https://www.hualigs.cn/image/60a0e62c77916.jpg" alt=""></p>          </div>]]></content>
      
    </entry>
    
    
  
</search>
